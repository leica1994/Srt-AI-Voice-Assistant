"""
è§†é¢‘å˜é€Ÿå¤„ç†å·¥å…·
æ ¹æ®åŸå­—å¹•å’Œæ–°å­—å¹•çš„æ—¶é•¿å·®å¼‚å¯¹è§†é¢‘è¿›è¡Œå˜é€Ÿå¤„ç†
"""

import gc
import os
import re
import datetime
import hashlib
import shutil
from typing import Dict, List, Optional
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

import ffmpeg
import platform
import subprocess


class VideoSpeedAdjuster:
    """è§†é¢‘å˜é€Ÿå¤„ç†å™¨"""

    def __init__(self, output_dir: str = None, max_workers: int = 4, use_gpu: bool = True):
        """
        åˆå§‹åŒ–è§†é¢‘å˜é€Ÿå¤„ç†å™¨

        Args:
            output_dir: è¾“å‡ºç›®å½•
            max_workers: æœ€å¤§å¹¶å‘å¤„ç†æ•°
            use_gpu: æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
        """
        if output_dir is not None:
            self.output_dir = Path(output_dir)
            self.output_dir.mkdir(exist_ok=True)

        self.max_workers = max_workers
        self.session_id = hashlib.md5(f"{datetime.datetime.now().isoformat()}".encode()).hexdigest()[:8]
        self.temp_dir = Path(f"temp_video_{self.session_id}")
        self.temp_dir.mkdir(exist_ok=True)

        # æ£€æµ‹GPUç¼–ç å™¨
        self.gpu_encoder = self._detect_gpu_encoder() if use_gpu else None

        print(f"ğŸš€ VideoSpeedAdjuster initialized")
        if hasattr(self, 'output_dir'):
            print(f"ğŸ“ Output: {self.output_dir}")
        else:
            print(f"ğŸ“ Output: Not specified")
        print(f"âš¡ Workers: {self.max_workers}")
        if self.gpu_encoder:
            print(f"ğŸ® GPU: {self.gpu_encoder}")
        else:
            print(f"ğŸ’» CPU encoding")

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.cleanup()

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if self.temp_dir.exists():
                shutil.rmtree(self.temp_dir)
                print(f"ğŸ§¹ Cleaned up: {self.temp_dir}")
        except Exception as e:
            print(f"âš ï¸ Cleanup failed: {e}")
        gc.collect()

    def _detect_gpu_encoder(self) -> Optional[str]:
        """æ£€æµ‹GPUç¼–ç å™¨"""
        encoders = ["h264_nvenc", "h264_qsv", "h264_amf"] if platform.system() == "Windows" else ["h264_nvenc"]

        for encoder in encoders:
            try:
                cmd = ["ffmpeg", "-f", "lavfi", "-i", "testsrc=duration=1:size=320x240:rate=1",
                       "-c:v", encoder, "-t", "1", "-f", "null", "-"]
                if subprocess.run(cmd, capture_output=True, timeout=3).returncode == 0:
                    return encoder
            except:
                continue
        return None

    def parse_srt_file(self, srt_path: str) -> List[Dict]:
        """
        è§£æSRTå­—å¹•æ–‡ä»¶
        
        Args:
            srt_path: SRTæ–‡ä»¶è·¯å¾„
            
        Returns:
            List[Dict]: å­—å¹•æ¡ç›®åˆ—è¡¨
        """
        if not os.path.exists(srt_path):
            raise FileNotFoundError(f"SRT file not found: {srt_path}")

        encodings = ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'cp1252']
        content = None

        for encoding in encodings:
            try:
                with open(srt_path, 'r', encoding=encoding) as file:
                    content = file.read()
                print(f"âœ… SRT file loaded with {encoding} encoding: {Path(srt_path).name}")
                break
            except UnicodeDecodeError:
                continue

        if content is None:
            raise RuntimeError(f"Could not decode SRT file with any supported encoding")

        subtitles = []
        for block in content.strip().split('\n\n'):
            lines = [line.strip() for line in block.split('\n') if line.strip()]
            if len(lines) < 3:
                continue

            try:
                number = int(lines[0])
                start_time, end_time = lines[1].split(' --> ')
                start_time = self._parse_timestamp(start_time)
                end_time = self._parse_timestamp(end_time)
                duration = (end_time - start_time).total_seconds()
                text = ' '.join(lines[2:])

                # æ¸…ç†æ–‡æœ¬ä¸­çš„æ ‡è®°
                text = re.sub(r'[ï¼ˆ\(][^ï¼‰\)]*[ï¼‰\)]', '', text).strip()
                text = text.replace('-', '').strip()

                subtitles.append({
                    'number': number,
                    'start_time': start_time,
                    'end_time': end_time,
                    'duration': duration,
                    'text': text,
                    'start_seconds': self._timestamp_to_seconds(start_time),
                    'end_seconds': self._timestamp_to_seconds(end_time)
                })
            except (ValueError, IndexError) as e:
                print(f"âš ï¸ Warning: Failed to parse subtitle block: {e}")
                continue

        print(f"âœ… Parsed {len(subtitles)} subtitle entries from {Path(srt_path).name}")
        return subtitles

    def _parse_timestamp(self, timestamp_str: str) -> datetime.datetime:
        """è§£æSRTæ—¶é—´æˆ³"""
        timestamp_str = timestamp_str.replace(',', '.')
        return datetime.datetime.strptime(timestamp_str, '%H:%M:%S.%f')

    def _timestamp_to_seconds(self, timestamp: datetime.datetime) -> float:
        """å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºç§’æ•°"""
        return (timestamp.hour * 3600 + timestamp.minute * 60 +
                timestamp.second + timestamp.microsecond / 1000000)

    def get_video_duration(self, video_path: str) -> float:
        """
        è·å–è§†é¢‘æ€»æ—¶é•¿

        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            float: è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        try:
            # ä½¿ç”¨ FFmpeg è·å–è§†é¢‘æ—¶é•¿
            probe = ffmpeg.probe(video_path)
            duration = float(probe['streams'][0]['duration'])
            print(f"ğŸ¬ Video duration: {duration:.2f} seconds")
            return duration
        except Exception as e:
            raise RuntimeError(f"Failed to get video duration: {e}")

    def validate_subtitles(self, original_subs: List[Dict], new_subs: List[Dict]) -> bool:
        """
        éªŒè¯ä¸¤ä¸ªå­—å¹•æ–‡ä»¶çš„å…¼å®¹æ€§
        
        Args:
            original_subs: åŸå­—å¹•åˆ—è¡¨
            new_subs: æ–°å­—å¹•åˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦å…¼å®¹
        """
        if len(original_subs) != len(new_subs):
            raise ValueError(f"Subtitle count mismatch: original={len(original_subs)}, new={len(new_subs)}")

        # æ£€æŸ¥å­—å¹•ç¼–å·æ˜¯å¦å¯¹åº”
        for i, (orig, new) in enumerate(zip(original_subs, new_subs)):
            if orig['number'] != new['number']:
                print(f"âš ï¸ Warning: Subtitle number mismatch at index {i}: {orig['number']} vs {new['number']}")

        print(f"âœ… Subtitle validation passed: {len(original_subs)} entries")
        return True

    def calculate_speed_segments(self, original_subs: List[Dict], new_subs: List[Dict],
                                 video_duration: float) -> List[Dict]:
        """
        è®¡ç®—æ¯ä¸ªç‰‡æ®µçš„å˜é€Ÿå‚æ•°
        
        Args:
            original_subs: åŸå­—å¹•åˆ—è¡¨
            new_subs: æ–°å­—å¹•åˆ—è¡¨
            video_duration: è§†é¢‘æ€»æ—¶é•¿
            
        Returns:
            List[Dict]: ç‰‡æ®µå˜é€Ÿä¿¡æ¯åˆ—è¡¨
        """
        segments = []
        segment_index = 0

        # æ£€æŸ¥ç¬¬ä¸€è¡Œå­—å¹•æ˜¯å¦ä»0å¼€å§‹ï¼Œå¦‚æœä¸æ˜¯åˆ™æ·»åŠ å¼€å¤´ç‰‡æ®µ
        first_subtitle_start = original_subs[0]['start_seconds'] if original_subs else 0
        if first_subtitle_start > 0.1:  # å¦‚æœç¬¬ä¸€è¡Œå­—å¹•å¼€å§‹æ—¶é—´å¤§äº0.1ç§’
            segments.append({
                'index': segment_index,
                'subtitle_number': 0,  # ç‰¹æ®Šæ ‡è®°ä¸ºå¼€å¤´ç‰‡æ®µ
                'start_time': 0,
                'end_time': first_subtitle_start,
                'original_duration': first_subtitle_start,
                'target_duration': first_subtitle_start,  # å¼€å¤´ç‰‡æ®µä¿æŒåŸé€Ÿåº¦
                'speed_ratio': 1.0,
                'original_text': '[å¼€å¤´ç‰‡æ®µ]',
                'new_text': '[å¼€å¤´ç‰‡æ®µ]'
            })
            segment_index += 1
            print(f"ğŸ“ Added opening segment: 0s - {first_subtitle_start:.2f}s")

        for i in range(len(original_subs)):
            orig_sub = original_subs[i]
            new_sub = new_subs[i]

            # è®¡ç®—åŸç‰‡æ®µçš„æ—¶é—´èŒƒå›´ï¼ˆä»å½“å‰å­—å¹•å¼€å§‹åˆ°ä¸‹ä¸€è¡Œå­—å¹•å¼€å§‹ï¼‰
            start_time = orig_sub['start_seconds']

            # ç»“æŸæ—¶é—´ï¼šä¸‹ä¸€ä¸ªå­—å¹•çš„å¼€å§‹æ—¶é—´ï¼Œæˆ–è§†é¢‘ç»“æŸæ—¶é—´
            if i < len(original_subs) - 1:
                end_time = original_subs[i + 1]['start_seconds']
            else:
                end_time = video_duration

            original_duration = end_time - start_time

            # ç›®æ ‡æ—¶é•¿ï¼šæ–°å­—å¹•å¯¹åº”ç‰‡æ®µçš„æ—¶é•¿ï¼ˆä»å½“å‰æ–°å­—å¹•å¼€å§‹åˆ°ä¸‹ä¸€è¡Œæ–°å­—å¹•å¼€å§‹ï¼Œæˆ–åˆ°ç»“æŸï¼‰
            new_start_time = new_sub['start_seconds']
            if i < len(new_subs) - 1:
                new_end_time = new_subs[i + 1]['start_seconds']
            else:
                # æœ€åä¸€è¡Œï¼šä»å¼€å§‹æ—¶é—´åˆ°ç»“æŸæ—¶é—´
                new_end_time = new_sub['end_seconds']

            target_duration = new_end_time - new_start_time

            # è®¡ç®—å˜é€Ÿæ¯”ä¾‹ï¼šéœ€è¦å°†åŸç‰‡æ®µæ—¶é•¿è°ƒæ•´ä¸ºæ–°å­—å¹•ç‰‡æ®µçš„æ—¶é•¿
            # speed_ratio = åŸæ—¶é•¿ / ç›®æ ‡æ—¶é•¿
            if target_duration > 0:
                speed_ratio = original_duration / target_duration
                # é™åˆ¶å˜é€Ÿæ¯”ä¾‹åœ¨åˆç†èŒƒå›´å†…ï¼ˆ0.25x - 4.0xï¼‰
                speed_ratio = max(0.25, min(4.0, speed_ratio))
            else:
                speed_ratio = 1.0
                print(f"âš ï¸ Warning: Zero target duration for subtitle {new_sub['number']}, using 1.0x speed")

            segments.append({
                'index': segment_index,
                'subtitle_number': orig_sub['number'],
                'start_time': start_time,
                'end_time': end_time,
                'original_duration': original_duration,
                'target_duration': target_duration,  # æ”¹åä¸ºtarget_durationæ›´æ¸…æ™°
                'speed_ratio': speed_ratio,
                'original_text': orig_sub['text'],
                'new_text': new_sub['text']
            })
            segment_index += 1

        # éªŒè¯è§†é¢‘å®Œæ•´æ€§
        self._verify_video_completeness(segments, video_duration)

        print(f"âœ… Calculated speed parameters for {len(segments)} segments")
        return segments

    def _verify_video_completeness(self, segments: List[Dict], video_duration: float):
        """éªŒè¯è§†é¢‘åˆ‡å‰²çš„å®Œæ•´æ€§"""
        print("ğŸ” Verifying video completeness...")

        if not segments:
            print("âŒ No segments found!")
            return

        # æŒ‰å¼€å§‹æ—¶é—´æ’åº
        sorted_segments = sorted(segments, key=lambda x: x['start_time'])

        # æ£€æŸ¥æ˜¯å¦ä»0å¼€å§‹
        first_start = sorted_segments[0]['start_time']
        if first_start > 0.1:
            print(f"âŒ Gap at beginning: 0s - {first_start:.2f}s")
        else:
            print(f"âœ… Starts from: {first_start:.2f}s")

        # æ£€æŸ¥ç‰‡æ®µé—´æ˜¯å¦æœ‰é—´éš”
        total_coverage = 0
        gaps = []
        overlaps = []

        for i, segment in enumerate(sorted_segments):
            start = segment['start_time']
            end = segment['end_time']
            duration = end - start
            total_coverage += duration

            print(f"   Segment {i + 1}: {start:.2f}s - {end:.2f}s (duration: {duration:.2f}s)")

            # æ£€æŸ¥ä¸ä¸‹ä¸€ä¸ªç‰‡æ®µçš„è¿æ¥
            if i < len(sorted_segments) - 1:
                next_start = sorted_segments[i + 1]['start_time']
                if end < next_start - 0.01:  # æœ‰é—´éš”
                    gap_duration = next_start - end
                    gaps.append((end, next_start, gap_duration))
                    print(f"   âš ï¸ Gap: {end:.2f}s - {next_start:.2f}s (duration: {gap_duration:.2f}s)")
                elif end > next_start + 0.01:  # æœ‰é‡å 
                    overlap_duration = end - next_start
                    overlaps.append((next_start, end, overlap_duration))
                    print(f"   âš ï¸ Overlap: {next_start:.2f}s - {end:.2f}s (duration: {overlap_duration:.2f}s)")

        # æ£€æŸ¥æ˜¯å¦è¦†ç›–åˆ°è§†é¢‘ç»“æŸ
        last_end = sorted_segments[-1]['end_time']
        if last_end < video_duration - 0.1:
            print(f"âŒ Missing end: {last_end:.2f}s - {video_duration:.2f}s")
        else:
            print(f"âœ… Ends at: {last_end:.2f}s (video: {video_duration:.2f}s)")

        # æ€»ç»“
        print(f"ğŸ“Š Coverage summary:")
        print(f"   Total segments: {len(segments)}")
        print(f"   Total coverage: {total_coverage:.2f}s")
        print(f"   Video duration: {video_duration:.2f}s")
        print(f"   Coverage ratio: {total_coverage / video_duration * 100:.1f}%")

        if gaps:
            print(f"   âŒ Found {len(gaps)} gaps")
        if overlaps:
            print(f"   âŒ Found {len(overlaps)} overlaps")

        if not gaps and not overlaps and abs(last_end - video_duration) < 0.1:
            print("âœ… Video completeness verified!")
        else:
            print("âŒ Video completeness issues detected!")

    def split_video_segment(self, video_path: str, start_time: float, end_time: float,
                            output_path: str) -> str:
        """åˆ†å‰²æ— å£°è§†é¢‘ç‰‡æ®µ"""
        try:
            duration = end_time - start_time
            input_stream = ffmpeg.input(video_path, ss=start_time, t=duration)

            # é€‰æ‹©ç¼–ç å™¨ï¼ˆæ— å£°è§†é¢‘ï¼Œä¸éœ€è¦éŸ³é¢‘ç¼–ç ï¼‰
            if self.gpu_encoder:
                output_stream = ffmpeg.output(input_stream, output_path, vcodec=self.gpu_encoder, **{'b:v': '2M'})
            else:
                output_stream = ffmpeg.output(input_stream, output_path, vcodec='libx264', crf=23)

            ffmpeg.run(output_stream, overwrite_output=True, quiet=True)
            return output_path

        except Exception as e:
            raise RuntimeError(f"Split failed: {e}")

    def adjust_video_speed(self, input_path: str, output_path: str, speed_ratio: float) -> str:
        """è°ƒæ•´æ— å£°è§†é¢‘æ’­æ”¾é€Ÿåº¦"""
        try:
            # æ¥è¿‘1.0å€é€Ÿç›´æ¥å¤åˆ¶
            if abs(speed_ratio - 1.0) < 0.01:
                shutil.copy2(input_path, output_path)
                return output_path

            # è°ƒæ•´è§†é¢‘é€Ÿåº¦ï¼ˆæ— å£°è§†é¢‘ï¼Œåªéœ€å¤„ç†è§†é¢‘æµï¼‰
            input_stream = ffmpeg.input(input_path)
            video_stream = input_stream.video.filter('setpts', f'{1 / speed_ratio:.6f}*PTS')

            if self.gpu_encoder:
                output_stream = ffmpeg.output(video_stream, output_path, vcodec=self.gpu_encoder, **{'b:v': '2M'})
            else:
                output_stream = ffmpeg.output(video_stream, output_path, vcodec='libx264', crf=23)

            ffmpeg.run(output_stream, overwrite_output=True, quiet=True)
            return output_path

        except Exception as e:
            raise RuntimeError(f"Speed adjust failed: {e}")

    def merge_video_audio(self, video_path: str, audio_path: str, output_path: str,
                          sync_to_audio: bool = True) -> str:
        """
        åˆæˆæ— å£°è§†é¢‘å’ŒéŸ³é¢‘ä¸ºå®Œæ•´è§†é¢‘ï¼ˆä¼˜åŒ–ç‰ˆï¼‰

        Args:
            video_path: æ— å£°è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆåŒæ—¶ä½œä¸ºå‚è€ƒè§†é¢‘è·å–æ ¼å¼ä¿¡æ¯ï¼‰
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            sync_to_audio: æ˜¯å¦å°†è§†é¢‘æ—¶é•¿åŒæ­¥åˆ°éŸ³é¢‘æ—¶é•¿

        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        try:
            print(f"ğŸ¬ Merging video and audio (optimized)...")
            print(f"   Video: {Path(video_path).name}")
            print(f"   Audio: {Path(audio_path).name}")

            # éªŒè¯è¾“å…¥æ–‡ä»¶
            if not os.path.exists(video_path):
                raise FileNotFoundError(f"Video file not found: {video_path}")
            if not os.path.exists(audio_path):
                raise FileNotFoundError(f"Audio file not found: {audio_path}")

            # è·å–è§†é¢‘å’ŒéŸ³é¢‘æ—¶é•¿
            video_duration = self.get_video_duration(video_path)
            audio_duration = self._get_audio_duration(audio_path)

            print(f"â±ï¸ Video duration: {video_duration:.2f}s")
            print(f"â±ï¸ Audio duration: {audio_duration:.2f}s")

            # è·å–å‚è€ƒè§†é¢‘ä¿¡æ¯å’Œç¼–ç å‚æ•°ï¼ˆä½¿ç”¨åŸè§†é¢‘ä½œä¸ºå‚è€ƒï¼‰
            video_codec, audio_codec, encoding_params = self._get_encoding_params(video_path)

            # æ„å»ºFFmpegæµ
            video_input = ffmpeg.input(video_path)
            audio_input = ffmpeg.input(audio_path)

            # æ ‡å‡†åˆæˆæ–¹å¼ï¼ˆè®©åå¤„ç†æ¥å¤„ç†æ—¶é•¿ä¸åŒ¹é…ï¼‰
            print(f"ğŸ”„ Standard merge...")
            if self.gpu_encoder:
                output_stream = ffmpeg.output(
                    video_input, audio_input, output_path,
                    vcodec=self.gpu_encoder,
                    acodec='aac',
                    **{'b:v': '2M'}
                )
            else:
                output_stream = ffmpeg.output(
                    video_input, audio_input, output_path,
                    vcodec='libx264',
                    acodec='aac',
                    crf=23
                )

            # æ‰§è¡Œåˆæˆ
            ffmpeg.run(output_stream, overwrite_output=True, quiet=True)

            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            if os.path.exists(output_path):
                output_duration = self.get_video_duration(output_path)
                print(f"âœ… Video-audio merge completed: {Path(output_path).name}")
                print(f"ğŸ“Š Output duration: {output_duration:.2f}s")

                # æ£€æŸ¥åŒæ­¥æ•ˆæœå¹¶è¿›è¡Œåå¤„ç†
                if sync_to_audio and audio_duration > output_duration + 0.5:
                    print(f"ğŸ”„ Video shorter than audio, extending video...")
                    success = self._extend_video_to_audio_length(output_path, audio_duration)
                    if success:
                        output_duration = self.get_video_duration(output_path)
                        print(f"âœ… Video extended to: {output_duration:.2f}s")

                sync_diff = abs(output_duration - audio_duration)
                if sync_diff < 0.1:
                    print(f"ğŸ¯ Perfect sync: Â±{sync_diff:.2f}s")
                else:
                    print(f"âš ï¸ Sync difference: {sync_diff:.2f}s")
            else:
                raise RuntimeError("Output file was not created")

            return output_path

        except Exception as e:
            raise RuntimeError(f"Failed to merge video and audio: {e}")

    def _extend_video_to_audio_length(self, video_path: str, target_duration: float) -> bool:
        """
        å»¶é•¿è§†é¢‘åˆ°æŒ‡å®šæ—¶é•¿ï¼ˆé€šè¿‡é‡å¤æœ€åä¸€å¸§ï¼‰

        Args:
            video_path: è¾“å…¥è§†é¢‘è·¯å¾„
            target_duration: ç›®æ ‡æ—¶é•¿

        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            extended_path = video_path.replace('.mp4', '_extended.mp4')

            # è·å–å½“å‰è§†é¢‘æ—¶é•¿
            current_duration = self.get_video_duration(video_path)
            extend_duration = target_duration - current_duration

            print(
                f"   Current: {current_duration:.2f}s, Target: {target_duration:.2f}s, Extend: {extend_duration:.2f}s")

            # ä½¿ç”¨ç®€å•çš„æ–¹æ³•ï¼šåˆ›å»ºä¸€ä¸ªé™æ€å›¾åƒå¹¶ä¸åŸè§†é¢‘æ‹¼æ¥
            temp_image = self.temp_dir / "last_frame.png"

            # æå–æœ€åä¸€å¸§
            (
                ffmpeg
                .input(video_path, ss=current_duration - 0.1)
                .output(str(temp_image), vframes=1)
                .run(overwrite_output=True, quiet=True)
            )

            # åˆ›å»ºå»¶é•¿çš„é™æ€è§†é¢‘ç‰‡æ®µ
            temp_static = self.temp_dir / "static_extension.mp4"
            print(f"   Creating {extend_duration:.2f}s extension...")
            (
                ffmpeg
                .input(str(temp_image), loop=1, t=extend_duration, framerate=25)
                .output(str(temp_static), vcodec='libx264', pix_fmt='yuv420p')
                .run(overwrite_output=True, quiet=True)
            )

            # æ‹¼æ¥åŸè§†é¢‘å’Œå»¶é•¿ç‰‡æ®µ
            filelist_path = self.temp_dir / "extend_filelist.txt"
            with open(filelist_path, 'w', encoding='utf-8') as f:
                f.write(f"file '{os.path.abspath(video_path).replace(chr(92), '/')}'\n")
                f.write(f"file '{os.path.abspath(temp_static).replace(chr(92), '/')}'\n")

            (
                ffmpeg
                .input(str(filelist_path), format='concat', safe=0)
                .output(extended_path, vcodec='copy')
                .run(overwrite_output=True, quiet=True)
            )

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for temp_file in [temp_image, temp_static, filelist_path]:
                if temp_file.exists():
                    temp_file.unlink()

            # æ›¿æ¢åŸæ–‡ä»¶
            if os.path.exists(extended_path):
                os.replace(extended_path, video_path)
                return True
            else:
                return False

        except Exception as e:
            print(f"âš ï¸ Failed to extend video: {e}")
            return False

    def _get_audio_duration(self, audio_path: str) -> float:
        """è·å–éŸ³é¢‘æ—¶é•¿"""
        try:
            probe = ffmpeg.probe(audio_path)
            for stream in probe['streams']:
                if stream['codec_type'] == 'audio':
                    return float(stream['duration'])
            raise RuntimeError("No audio stream found")
        except Exception as e:
            raise RuntimeError(f"Failed to get audio duration: {e}")

    def _get_encoding_params(self, reference_video_path: str = None) -> tuple:
        """è·å–ç¼–ç å‚æ•°"""
        video_codec = 'libx264'
        audio_codec = 'aac'
        encoding_params = {}

        # ä»å‚è€ƒè§†é¢‘è·å–ç¼–ç ä¿¡æ¯
        if reference_video_path and os.path.exists(reference_video_path):
            try:
                probe = ffmpeg.probe(reference_video_path)
                for stream in probe['streams']:
                    if stream['codec_type'] == 'video':
                        ref_codec = stream['codec_name']
                        if ref_codec in ['h264', 'libx264']:
                            video_codec = 'libx264'
                        elif ref_codec in ['h265', 'hevc', 'libx265']:
                            video_codec = 'libx265'

                        # è·å–æ›´å¤šå‚æ•°
                        if 'bit_rate' in stream:
                            bitrate = int(stream['bit_rate']) // 1000  # è½¬æ¢ä¸ºkbps
                            encoding_params['b:v'] = f'{min(bitrate, 5000)}k'  # é™åˆ¶æœ€å¤§æ¯”ç‰¹ç‡
                        break

                print(f"ğŸ“‹ Reference codec: {ref_codec} â†’ Using: {video_codec}")
            except Exception as e:
                print(f"âš ï¸ Could not read reference video info: {e}")

        # GPUç¼–ç å™¨ç‰¹å®šå‚æ•°
        if self.gpu_encoder:
            if self.gpu_encoder == "h264_nvenc":
                encoding_params.update({
                    'preset': 'fast',
                    'profile:v': 'high',
                    'level': '4.1'
                })
            elif self.gpu_encoder == "h264_qsv":
                encoding_params.update({
                    'preset': 'medium',
                    'profile:v': 'high'
                })

        # å¦‚æœæ²¡æœ‰è®¾ç½®æ¯”ç‰¹ç‡ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if 'b:v' not in encoding_params:
            encoding_params['b:v'] = '2M'

        return video_codec, audio_codec, encoding_params

    def process_segment(self, video_path: str, segment: Dict, segment_dir: Path) -> Dict:
        """
        å¤„ç†å•ä¸ªè§†é¢‘ç‰‡æ®µ

        Args:
            video_path: åŸè§†é¢‘è·¯å¾„
            segment: ç‰‡æ®µä¿¡æ¯
            segment_dir: ç‰‡æ®µè¾“å‡ºç›®å½•

        Returns:
            Dict: å¤„ç†ç»“æœ
        """
        try:
            index = segment['index']
            start_time = segment['start_time']
            end_time = segment['end_time']
            speed_ratio = segment['speed_ratio']

            # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶å
            temp_segment = segment_dir / f"temp_segment_{index:04d}.mp4"
            final_segment = segment_dir / f"segment_{index:04d}.mp4"

            original_dur = segment['original_duration']
            target_dur = segment['target_duration']
            print(
                f"ğŸ¬ Segment {index + 1}: {start_time:.2f}s-{end_time:.2f}s (åŸ{original_dur:.2f}sâ†’ç›®æ ‡{target_dur:.2f}s, {speed_ratio:.2f}x)")

            # æ­¥éª¤1: åˆ†å‰²è§†é¢‘ç‰‡æ®µ
            self.split_video_segment(video_path, start_time, end_time, str(temp_segment))

            # æ­¥éª¤2: è°ƒæ•´æ’­æ”¾é€Ÿåº¦
            if abs(speed_ratio - 1.0) > 0.01:  # åªæœ‰å½“é€Ÿåº¦æ¯”ä¾‹ä¸æ˜¯1.0æ—¶æ‰è°ƒæ•´
                self.adjust_video_speed(str(temp_segment), str(final_segment), speed_ratio)
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                temp_segment.unlink()
            else:
                # å¦‚æœä¸éœ€è¦å˜é€Ÿï¼Œç›´æ¥é‡å‘½å
                temp_segment.rename(final_segment)

            return {
                'index': index,
                'success': True,
                'output_path': str(final_segment),
                'speed_ratio': speed_ratio,
                'message': f"Segment {index + 1} processed successfully"
            }

        except Exception as e:
            return {
                'index': segment['index'],
                'success': False,
                'output_path': None,
                'speed_ratio': segment['speed_ratio'],
                'message': f"Failed to process segment {segment['index'] + 1}: {e}"
            }

    def concatenate_videos(self, segment_paths: List[str], output_path: str) -> str:
        """æ‹¼æ¥æ— å£°è§†é¢‘ç‰‡æ®µ"""
        try:
            print(f"ğŸ”— Concatenating {len(segment_paths)} segments...")

            # åˆ›å»ºæ–‡ä»¶åˆ—è¡¨
            filelist_path = self.temp_dir / "filelist.txt"
            with open(filelist_path, 'w', encoding='utf-8') as f:
                for path in segment_paths:
                    abs_path = os.path.abspath(path).replace('\\', '/')
                    f.write(f"file '{abs_path}'\n")

            # å°è¯•ç›´æ¥æ‹¼æ¥
            try:
                input_stream = ffmpeg.input(str(filelist_path), format='concat', safe=0)
                output_stream = ffmpeg.output(input_stream, output_path, vcodec='copy')
                ffmpeg.run(output_stream, overwrite_output=True, quiet=True)
                print(f"âœ… Concatenated (stream copy)")
            except Exception:
                # é‡ç¼–ç æ‹¼æ¥
                print("âš ï¸ Re-encoding...")
                input_stream = ffmpeg.input(str(filelist_path), format='concat', safe=0)

                if self.gpu_encoder:
                    output_stream = ffmpeg.output(input_stream, output_path, vcodec=self.gpu_encoder, **{'b:v': '2M'})
                else:
                    output_stream = ffmpeg.output(input_stream, output_path, vcodec='libx264', crf=23)

                ffmpeg.run(output_stream, overwrite_output=True, quiet=True)
                print(f"âœ… Concatenated ({'GPU' if self.gpu_encoder else 'CPU'})")

            return output_path

        except Exception as e:
            raise RuntimeError(f"Concatenate failed: {e}")

    def process_video_with_speed_adjustment(self, video_path: str, original_srt_path: str,
                                            new_srt_path: str, output_path: str = None) -> Dict:
        """ä¸»å¤„ç†å‡½æ•°ï¼šæ ¹æ®å­—å¹•å·®å¼‚å¯¹æ— å£°è§†é¢‘è¿›è¡Œå˜é€Ÿå¤„ç†"""
        try:
            print(f"ğŸš€ Processing: {Path(video_path).name}")

            # éªŒè¯æ–‡ä»¶å­˜åœ¨
            for file_path in [video_path, original_srt_path, new_srt_path]:
                if not os.path.exists(file_path):
                    raise FileNotFoundError(f"File not found: {file_path}")

            # è§£æå­—å¹•
            original_subs = self.parse_srt_file(original_srt_path)
            new_subs = self.parse_srt_file(new_srt_path)
            self.validate_subtitles(original_subs, new_subs)

            # è®¡ç®—å˜é€Ÿå‚æ•°
            video_duration = self.get_video_duration(video_path)
            segments = self.calculate_speed_segments(original_subs, new_subs, video_duration)

            # å¹¶è¡Œå¤„ç†ç‰‡æ®µ
            print(f"âš¡ Processing {len(segments)} segments...")
            segment_dir = self.temp_dir / "segments"
            segment_dir.mkdir(exist_ok=True)

            processed_segments = []
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                future_to_segment = {
                    executor.submit(self.process_segment, video_path, segment, segment_dir): segment
                    for segment in segments
                }

                for future in as_completed(future_to_segment):
                    result = future.result()
                    if result['success']:
                        processed_segments.append(result)
                    else:
                        print(f"âŒ {result['message']}")

            if len(processed_segments) != len(segments):
                raise RuntimeError(f"Failed segments: {len(segments) - len(processed_segments)}")

            # æ‹¼æ¥è§†é¢‘
            processed_segments.sort(key=lambda x: x['index'])
            segment_paths = [seg['output_path'] for seg in processed_segments]

            if output_path is None:
                output_path = self.output_dir / f"{Path(video_path).stem}_speed_adjusted.mp4"

            final_output = self.concatenate_videos(segment_paths, str(output_path))

            # ç»Ÿè®¡ä¿¡æ¯
            total_original = sum(seg['original_duration'] for seg in segments)
            total_target = sum(seg['target_duration'] for seg in segments)
            avg_speed = total_original / total_target if total_target > 0 else 1.0

            print(f"ğŸ‰ Completed! {len(processed_segments)}/{len(segments)} segments")
            print(f"â±ï¸ Original: {total_original:.2f}s â†’ Target: {total_target:.2f}s (avg {avg_speed:.2f}x)")
            print(f"ğŸ’¾ Output: {final_output}")

            return {
                'success': True,
                'output_path': final_output,
                'segments_processed': len(processed_segments),
                'total_segments': len(segments),
                'original_duration': total_original,
                'target_duration': total_target,  # æ”¹ä¸ºtarget_duration
                'average_speed_ratio': avg_speed,
                'message': "Success"
            }

        except Exception as e:
            print(f"âŒ Failed: {e}")
            return {
                'success': False,
                'output_path': None,
                'segments_processed': 0,
                'total_segments': 0,
                'message': str(e)
            }


def adjust_video_speed_by_subtitles(video_path: str, original_srt_path: str, new_srt_path: str,
                                    output_path: str = None, output_dir: str = "output",
                                    max_workers: int = 4, use_gpu: bool = True) -> Dict:
    """
    æ ¹æ®å­—å¹•å·®å¼‚è°ƒæ•´æ— å£°è§†é¢‘æ’­æ”¾é€Ÿåº¦

    Args:
        video_path: æ— å£°è§†é¢‘æ–‡ä»¶è·¯å¾„
        original_srt_path: åŸå­—å¹•æ–‡ä»¶è·¯å¾„
        new_srt_path: æ–°å­—å¹•æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        max_workers: æœ€å¤§å¹¶å‘å¤„ç†æ•°
        use_gpu: æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ

    Returns:
        Dict: å¤„ç†ç»“æœ
    """
    with VideoSpeedAdjuster(output_dir=output_dir, max_workers=max_workers, use_gpu=use_gpu) as adjuster:
        return adjuster.process_video_with_speed_adjustment(
            video_path, original_srt_path, new_srt_path, output_path
        )


def merge_video_with_audio(video_path: str, audio_path: str, output_path: str,
                           use_gpu: bool = True, sync_to_audio: bool = True) -> str:
    """
    åˆæˆæ— å£°è§†é¢‘å’ŒéŸ³é¢‘çš„ä¾¿æ·å‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰

    Args:
        video_path: æ— å£°è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆåŒæ—¶ä½œä¸ºå‚è€ƒè§†é¢‘è·å–æ ¼å¼ä¿¡æ¯ï¼‰
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        use_gpu: æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
        sync_to_audio: æ˜¯å¦å°†è§†é¢‘æ—¶é•¿åŒæ­¥åˆ°éŸ³é¢‘æ—¶é•¿

    Returns:
        str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # ä»è¾“å‡ºè·¯å¾„è·å–è¾“å‡ºç›®å½•
    output_dir = os.path.dirname(output_path)
    with VideoSpeedAdjuster(output_dir=output_dir, use_gpu=use_gpu) as adjuster:
        return adjuster.merge_video_audio(video_path, audio_path, output_path, sync_to_audio)
